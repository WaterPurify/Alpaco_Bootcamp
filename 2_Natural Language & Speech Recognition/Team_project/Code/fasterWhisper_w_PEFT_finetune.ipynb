{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WaterPurify/Alpaco_Bootcamp/blob/main/2_Natural%20Language%20%26%20Speech%20Recognition/Team_project/Code/fasterWhisper_w_PEFT_finetune_version1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cefac89",
      "metadata": {
        "id": "5cefac89"
      },
      "source": [
        "# LoRA (Low Rank Adaptation) ì™€ PEFT (Paramater Efficient Fine Tuning)ë¥¼ ì ìš©í•œ Larger Whisper fine-tuning âš¡ï¸\n",
        "\n",
        "* ì†Œë¹„ì GPUì˜ VRAMì´ 8GB ë¯¸ë§Œì¸ í™˜ê²½ì—ì„œë„ full-finetuningê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ì œê³µí•¨\n",
        "*  ğŸ¤— Transformers and PEFT ëª¨ë¸ê³¼ Common Voice 13.0 datasetë¥¼ ì‚¬ìš©í•˜ì—¬ Whisper fine-tuneí•˜ëŠ” ê³¼ì • ì„¤ëª…í•¨\n",
        "* PEFTì™€ bitsandbytesë¥¼ í™œìš©í•˜ì—¬ ë¬´ë£Œ T4 GPU(16GB VRAM)ë¥¼ ì‚¬ìš©í•˜ì—¬ whisper-large-v2 ì²´í¬í¬ì¸íŠ¸ë¥¼ ì›í™œí•˜ê²Œ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i7DzwD7oYDPf",
      "metadata": {
        "id": "i7DzwD7oYDPf"
      },
      "source": [
        "## ì™œ Parameter Efficient Fine Tuning [PEFT](https://github.com/huggingface/peft)ë¥¼ ì‚¬ìš©í•´ì•¼ ë˜ëŠ”ê°€?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZAMw8FIuYMF-",
      "metadata": {
        "id": "ZAMw8FIuYMF-"
      },
      "source": [
        "* ëª¨ë¸ ì‚¬ì´ì¦ˆ ì¦ê°€ë¡œ fine tuningí•˜ëŠ” ê²ƒì´ ê³„ì‚° ë³µì¡ì„± ì¦ê°€ì™€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€\n",
        "    * ì˜ˆë¥¼ ë“¤ì–´, Whisper-large-v2 ëª¨ë¸ì„ ì™„ì „í•œ ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•´ ì•½ 24GBì˜ GPU VRAMì´ í•„ìš”í•˜ë©°, ê° ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì€ ì•½ 7GBì˜ ì €ì¥ ê³µê°„ì„ í•„ìš”í•¨\n",
        "\n",
        "    * ì œí•œì ì¸ í™˜ê²½ì—ì„œ bottleneck ë°œìƒí•˜ê³  ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ê¸° í˜ë“¦\n",
        "* PEFT\n",
        "    * íš¨ê³¼ì ìœ¼ë¡œ parameterë¥¼ ì¤„ì—¬ì„œ fine tuning ì†ë„ ê°œì„ \n",
        "    * ëª©ì : ë³‘ëª© í˜„ìƒì„ í•´ê²°\n",
        "    * ì ‘ê·¼ë²•(ì˜ˆ: ì €ìˆ˜ì¤€ ì ì‘): ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì˜ ëŒ€ë¶€ë¶„ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ë™ê²°ì‹œí‚¤ë©´ì„œ ì¶”ê°€ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ì˜ ì¼ë¶€ë§Œ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ê³„ì‚° ë° ì €ì¥ ë¹„ìš© í¬ê²Œ ì¤„ì„\n",
        "        * ëŒ€ê·œëª¨ ëª¨ë¸ì˜ ì „ì²´ ë¯¸ì„¸ ì¡°ì • ì¤‘ ê´€ì°°ë˜ëŠ” catastrophic forgetting ë¬¸ì œë¥¼ ê·¹ë³µí•  ìˆ˜ ìˆìŒ\n",
        "\n",
        "### LoRAê°€ ë¬´ì—‡ì¸ê°€?\n",
        "\n",
        "* PEFTì—ì„œ ì—¬ëŸ¬ ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì ì¸ ê¸°ìˆ ì„ ê¸°ë³¸ìœ¼ë¡œ ì œê³µ\n",
        "    * ê·¸ ì¤‘ í•˜ë‚˜ì¸ Low Rank Adaptation (LoRA)\n",
        "        * ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë™ê²°í•˜ê³  Transformer ì•„í‚¤í…ì²˜ì˜ ê° ë ˆì´ì–´ì— í›ˆë ¨ ê°€ëŠ¥í•œ ë­í¬ ë¶„í•´ í–‰ë ¬ì„ ì‚½ì… (High Rank ì¦‰ ë§ì€ ì—°ê²°ì´ ë˜ì–´ ìˆëŠ” ê²ƒë“¤ë³´ë‹¤ ì—°ê²°ì´ ì ì€ Low Rankë¡œ ë§Œë“¤ì–´ì„œ ê³„ì‚°ëŸ‰ì„ ì¤„ì„)\n",
        "            * Downstream ì‘ì—…ì— ëŒ€í•œ í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ ìˆ˜ê°€ í¬ê²Œ ê°ì†Œ\n",
        "\n",
        "### í†µê³„ë¡œ ë³´ëŠ” PEFT íš¨ê³¼\n",
        "\n",
        "* Full fine-tuning of Whisper-large-v2 checkpoint Vs. PEFT ì ìš© ëª¨ë¸\n",
        "\n",
        "    1. GPU VRAMì´ 8GB ë¯¸ë§Œì¸ í™˜ê²½ì—ì„œ 16ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì • ğŸ¤¯\n",
        "    2. í›¨ì”¬ ì ì€ ìˆ˜ì˜ í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê±°ì˜ 5ë°° ë” í° ë°°ì¹˜ í¬ê¸°ë¥¼ ì‚¬ìš© ê°€ëŠ¥ ğŸ“ˆ\n",
        "    3. ìƒì„±ëœ ì²´í¬í¬ì¸íŠ¸ëŠ” ì›ë³¸ ëª¨ë¸ì˜ í¬ê¸°ì˜ 1%ì¸ ì•½ 60MB ğŸš€\n",
        "* ê¸°ì¡´ ğŸ¤— transformers Whisperì—ì„œ ë³€í˜•ì´ ë§ì´ ë˜ì§€ ì•Šì•˜ìŒ\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625e47a0",
      "metadata": {
        "id": "625e47a0"
      },
      "source": [
        "## í™˜ê²½ì„¤ì •\n",
        "\n",
        "\n",
        "* Python package->Whisper ëª¨ë¸ fine tuningí•˜ê¸° ìœ„í•´ ì‚¬ìš©\n",
        "  * `datasets`:í•™ìŠµ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¤€ë¹„\n",
        "  * `transformers`: Whisper ëª¨ë¸ì„ ë¡œë“œí•˜ê³  í›ˆë ¨\n",
        "  * `librosa`: ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì „ì²˜ë¦¬\n",
        "  * `evaluate` &  `jiwer`:ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€\n",
        "  * `PEFT`, `bitsandbytes`, `accelerate`: LoRAë¡œ ëª¨ë¸ê³¼ fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r_Ivl7qlX0dz",
      "metadata": {
        "id": "r_Ivl7qlX0dz"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/peft.git@main"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xbGqOmtMw4NR",
      "metadata": {
        "id": "xbGqOmtMw4NR"
      },
      "source": [
        "\n",
        "* GPU í™•ë³´\n",
        "    * Google Colab Pro: V100 ë˜ëŠ” P100 GPUê°€ í• ë‹¹\n",
        "* GPU í™•ë³´ ë°©ë²•\n",
        "    * ëŸ°íƒ€ì„ -> ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½\n",
        "    * None -> GPU ë³€ê²½\n",
        "* GPU í• ë‹¹ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2kBtM9XSjKE5",
      "metadata": {
        "id": "2kBtM9XSjKE5",
        "outputId": "3b93497c-4c08-4c17-c23e-3625dab455e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Apr 26 09:50:49 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   49C    P0             33W /  135W |       0MiB /   8192MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6WwnavbBuezQ",
      "metadata": {
        "id": "6WwnavbBuezQ"
      },
      "source": [
        "Colabì—ì„œ ì œê³µí•˜ëŠ” GPUì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1da5fff",
      "metadata": {
        "id": "e1da5fff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a528c1a",
      "metadata": {
        "id": "8a528c1a"
      },
      "source": [
        "We strongly advise you to upload model checkpoints directly the [Hugging Face Hub](https://huggingface.co/)\n",
        "whilst training. The Hub provides:\n",
        "- Integrated version control: you can be sure that no model checkpoint is lost during training.\n",
        "- Tensorboard logs: track important metrics over the course of training.\n",
        "- Model cards: document what a model does and its intended use cases.\n",
        "- Community: an easy way to share and collaborate with the community!\n",
        "\n",
        "\n",
        "* í•™ìŠµ ì¤‘ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì§ì ‘ Hugging Face Hubì— ì—…ë¡œë“œí•˜ëŠ” ê²ƒì„ ê°•ë ¥íˆ ê¶Œì¥\n",
        " * Hubë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µ:\n",
        "\n",
        " 1. í†µí•©ëœ ë²„ì „ ê´€ë¦¬: í›ˆë ¨ ì¤‘ì— ì–´ë– í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë„ ì†ì‹¤ë˜ì§€ ì•ŠìŒ\n",
        " 2. Tensorboard ë¡œê·¸: í›ˆë ¨ ê³¼ì •ì—ì„œ ì¤‘ìš”í•œ ì§€í‘œë¥¼ ì¶”ì \n",
        " 3. ëª¨ë¸ ì¹´ë“œ: ëª¨ë¸ì´ ë¬´ì—‡ì„ í•˜ê³  ì˜ë„ëœ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ë¬¸ì„œí™”\n",
        " 4. ì»¤ë®¤ë‹ˆí‹°: ì»¤ë®¤ë‹ˆí‹°ì™€ ì‰½ê²Œ ê³µìœ í•˜ê³  í˜‘ì—…\n",
        "\n",
        "* Hubì— ì—°ê²°\n",
        " * í”„ë¡¬í”„íŠ¸ì—ì„œ Hub ì¸ì¦ í† í°ì„ ì…ë ¥:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0OpduhX2JF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8dcb31625fff4f7da6d28821ef535958",
            "de61db8206fe4a6da225263fe67d6fda",
            "33b8358abdd84d2db2a676cd78e34e24",
            "9f7069bb8321494eb6d8184eade793f3",
            "49d1a842d5374d7d90223a895dad23a1",
            "ee3a40d801654eb7957204287584baca",
            "11ebc9c8a98a471fae03bbf78f266017",
            "eb5347528f2440279d88be725e435df7",
            "ee04cb67adc24431b9279db5dbfcd233",
            "e96669dc833348558eaba0a863000992",
            "32268d5cfdbf4cada7ecf99f500d78e3",
            "06292a5c7aee497da4adf4bad7821023",
            "d278e3ffc1504e5790aaf4250bbdc0fb",
            "d7f2b46662614e7a86d5bb40ec8dfbca",
            "4d28829ac5fd43c0978fb4abdba1232a",
            "66b90e6bde694e819da181fc0536daf7",
            "948d115a19b446cd9f75a7e5b8210571",
            "74bfe188e1004755b580367771a08150",
            "1c6783f29c6d4473a1f2f6936fa8682a",
            "323d4ce1247e47ffa4d7402ae9d56187",
            "e6ad995b0183445eb165aff824a649fa",
            "8d7c7ef49aec459783389b840fe3a5c6",
            "2e39340a463a4a36aa5b89c468443340",
            "0941f6a14ce44d828a76bba404be355f"
          ]
        },
        "id": "ed0OpduhX2JF",
        "outputId": "ad965bd7-974f-4621-c149-013ca660095f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0941f6a14ce44d828a76bba404be355f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gG-2lYDPw3uW",
      "metadata": {
        "id": "gG-2lYDPw3uW"
      },
      "source": [
        "\n",
        "Whisper ëª¨ë¸ checkpointì™€ task ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mJ9M1WKhu0KM",
      "metadata": {
        "id": "mJ9M1WKhu0KM"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"openai/whisper-large-v2\"\n",
        "task = \"transcribe\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EuhppXc9xAt2",
      "metadata": {
        "id": "EuhppXc9xAt2"
      },
      "source": [
        "\n",
        "\n",
        "ë°ì´í„°ì…‹ ë””í…Œì¼ì„ ì„¤ì • (ì–¸ì–´)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7sE0FPf7w-he",
      "metadata": {
        "id": "7sE0FPf7w-he"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"mozilla-foundation/common_voice_13_0\"\n",
        "language = \"Korean\"\n",
        "language_abbr = \"ko\" # Short hand code for the language we want to fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XPI5OZz4u3b1",
      "metadata": {
        "id": "XPI5OZz4u3b1"
      },
      "source": [
        "# ë°ì´í„°ì…‹ ì˜¬ë¦¬ê¸°\n",
        "\n",
        "* Huggingface Dataset ì‚¬ìš©\n",
        " * ì ì€ ì½”ë“œë¡œ Common Voiceì˜ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¤€ë¹„\n",
        "\n",
        "* í™•ì¸ ì ˆì°¨\n",
        " 1. Hugging Face Hubì˜ ì´ìš© ì•½ê´€ì„ ìˆ˜ë½í–ˆëŠ”ì§€ í™•ì¸:[mozilla-foundation/common_voice_13_0](https://huggingface.co/datasets/mozilla-foundation/common_voice_13_0)\n",
        " 2. ë°ì´í„°ì…‹ì— ì•¡ì„¸ìŠ¤í•˜ê³  ë¡œì»¬ë¡œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ\n",
        "\n",
        "* í•™ìŠµ+ê²€ì¦ ë°ì´í„°ì…‹/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
        "outputId": "2d9c0a24-e1f9-40eb-c8be-67b421e4431a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
            "        num_rows: 297\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
            "        num_rows: 131\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(dataset_name, language_abbr, split=\"train+validation\", token=True)\n",
        "common_voice[\"test\"] = load_dataset(dataset_name, language_abbr, split=\"test\", token=True)\n",
        "\n",
        "print(common_voice)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "805b1c56",
      "metadata": {
        "id": "805b1c56"
      },
      "source": [
        "* ì¼ë°˜ì ì¸ ASR(ìŒì„± ì¸ì‹) ë°ì´í„°ì…‹\n",
        "    * ì…ë ¥ ì˜¤ë””ì˜¤ ìƒ˜í”Œ(ì˜¤ë””ì˜¤)ê³¼ í•´ë‹¹ë˜ëŠ” í…ìŠ¤íŠ¸(ë¬¸ì¥)ë§Œ ì œê³µ\n",
        "* Common Voice\n",
        "    * ASRì—ëŠ” í•„ìš”í•˜ì§€ ì•Šì€ ì•…ì„¼íŠ¸ì™€ ë¡œì¼€ì¼ê³¼ ê°™ì€ ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì •ë³´ê°€ í¬í•¨\n",
        "    * ì¼ë°˜ì ì¸ ìš©ë„ë¡œ ì‚¬ìš©í•˜ê³  ë¯¸ì„¸ ì¡°ì •ì„ ê³ ë ¤í•˜ê¸° ìœ„í•´ ë©”íƒ€ë°ì´í„° ì •ë³´ ë¬´ì‹œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ba635d-518c-47ac-97ee-3cad25f1e0ce",
      "metadata": {
        "id": "20ba635d-518c-47ac-97ee-3cad25f1e0ce",
        "outputId": "2b426cc2-57db-4af9-ffd6-786020ed96a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['audio', 'sentence'],\n",
            "        num_rows: 297\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['audio', 'sentence'],\n",
            "        num_rows: 131\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "common_voice = common_voice.remove_columns(\n",
        "    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\", \"variant\"]\n",
        ")\n",
        "\n",
        "print(common_voice)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605",
      "metadata": {
        "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605"
      },
      "source": [
        "## íŠ¹ì„± ì¶”ì¶œê¸°(Feature Extractor), í† í¬ë‚˜ì´ì €(Tokenizer), ê·¸ë¦¬ê³  ë°ì´í„°ì¤€ë¹„\n",
        "\n",
        "ASR íŒŒì´í”„ë¼ì¸ ì„¸ ë‹¨ê³„ë¡œ ë¶„í•´:\n",
        "\n",
        "1. Raw ì˜¤ë””ì˜¤ ì…ë ¥ì„ ì „ì²˜ë¦¬í•˜ëŠ” íŠ¹ì • ì¶”ì¶œê¸°\n",
        "2. ì‹œí€€ìŠ¤ ê°„ ë§¤í•‘ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸\n",
        "3. ëª¨ë¸ ì¶œë ¥ì„ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í›„ì²˜ë¦¬í•˜ëŠ” tokenizer\n",
        "\n",
        "\n",
        "* Whisper\n",
        "    * [WhisperFeatureExtractor](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperFeatureExtractor)ì™€ [WhisperTokenizer](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperTokenizer)ë¡œ êµ¬ì„±\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5",
      "metadata": {
        "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name_or_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b07f9b-ae0e-4f89-98f0-0c50d432eab6",
      "metadata": {
        "id": "c7b07f9b-ae0e-4f89-98f0-0c50d432eab6",
        "outputId": "6089bc99-7131-4638-c1fc-c9132971d2d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(model_name_or_path, language=language, task=task)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gIaGxWbXkcrC",
      "metadata": {
        "id": "gIaGxWbXkcrC"
      },
      "source": [
        "* WhisperProcessor í´ë¼ìŠ¤\n",
        "    * íŠ¹ì„± ì¶”ì¶œê¸°ì™€ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ë¥¼ ëª¨ë‘ í•©ì¹©\n",
        "    * í•„ìš”ì— ë”°ë¼ ì˜¤ë””ì˜¤ ì…ë ¥ ë° ëª¨ë¸ ì˜ˆì¸¡ì— ì‚¬ìš© ê°€ëŠ¥\n",
        "\n",
        "* í•™ìŠµ ì¤‘ì— ë‘ ê°œì˜ ê°ì²´ë§Œ ì¶”ì  í•„ìš”: í”„ë¡œì„¸ì„œì™€ ëª¨ë¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6",
      "metadata": {
        "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6",
        "outputId": "71f52347-9942-4e6c-d5f7-305cc0862127"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(model_name_or_path, language=language, task=task)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c",
      "metadata": {
        "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c"
      },
      "source": [
        "### ë°ì´í„° ì¤€ë¹„\n",
        "\n",
        "Common Voice ë°ì´í„°ì…‹ì˜ ì²« ë²ˆì§¸ ì˜ˆì œë¥¼ ì¶œë ¥í•˜ì—¬ ë°ì´í„°ì˜ í˜•ì‹ì„ ì‚´í´ë´„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6b0ec5-0c94-4e2c-ae24-c791be1b2255",
      "metadata": {
        "id": "6e6b0ec5-0c94-4e2c-ae24-c791be1b2255",
        "outputId": "902f73dc-35ff-4289-b420-00c2bd8bddf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'audio': {'path': 'C:\\\\Users\\\\User\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\f4cce98295bb5b9d65d17d7d495bef59577e50b412400821477bb56f2c098300\\\\ko_train_0/common_voice_ko_35845802.mp3', 'array': array([-4.54747351e-13,  4.77484718e-12,  6.59383659e-12, ...,\n",
            "        2.07564299e-05,  1.92765128e-06, -1.09442644e-05]), 'sampling_rate': 48000}, 'sentence': 'ì–´ëŠë§ ê·¸ ë”ìš´ íŒ”ì›”ë„ í•˜ë£¨ë¥¼ ë‚¨ê¸°ê³  ë‹¤ ì§€ë‚˜ ë²„ë ¸ë‹¤.'}\n"
          ]
        }
      ],
      "source": [
        "print(common_voice[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a679f05-063d-41b3-9b58-4fc9c6ccf4fd",
      "metadata": {
        "id": "5a679f05-063d-41b3-9b58-4fc9c6ccf4fd"
      },
      "source": [
        "* Whisper ëª¨ë¸ ìƒ˜í”Œë§\n",
        "    * ì…ë ¥ ì˜¤ë””ì˜¤ëŠ” 48 kHz ìƒˆí”Œë§\n",
        "    * Whisper feature extractorì— ì „ë‹¬í•˜ê¸° ìœ„í•´ì„œ 16 kHzë¡œ ë‹¤ìš´ìƒ˜í”Œ ì§„í–‰\n",
        "* ìƒ˜í”Œë§ ì†ë„ ì„¤ì •\n",
        "    * Datasetì˜ [`cast_column`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=cast_column#datasets.DatasetDict.cast_column) ë°©ë²• ì‚¬ìš©: ì˜¤ë””ì˜¤ ì…ë ¥ì„ ì˜¬ë°”ë¥¸ ìƒ˜í”Œë§ ì†ë„ë¡œ ì„¤ì •\n",
        "    * ì˜¤ë””ì˜¤ë¥¼ ë³€ê²½í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì˜¤ë””ì˜¤ ìƒ˜í”Œì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë„ë¡ í•¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12e2e57-156f-417b-8cfb-69221cc198e8",
      "metadata": {
        "id": "f12e2e57-156f-417b-8cfb-69221cc198e8"
      },
      "outputs": [],
      "source": [
        "from datasets import Audio\n",
        "\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00382a3e-abec-4cdd-a54c-d1aaa3ea4707",
      "metadata": {
        "id": "00382a3e-abec-4cdd-a54c-d1aaa3ea4707"
      },
      "source": [
        "\n",
        "Common Voice ë°ì´í„°ì…‹ì—ì„œ ì²« ë²ˆì§¸ ì˜¤ë””ì˜¤ ìƒ˜í”Œì„ ë‹¤ì‹œë¡œë“œí•˜ë©´ ì›í•˜ëŠ” ìƒ˜í”Œë§ ì†ë„ë¡œ ë‹¤ì‹œ ìƒ˜í”Œë§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87122d71-289a-466a-afcf-fa354b18946b",
      "metadata": {
        "id": "87122d71-289a-466a-afcf-fa354b18946b",
        "outputId": "ee834319-5f0c-44f6-cae8-80d2741a49b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'audio': {'path': 'C:\\\\Users\\\\User\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\f4cce98295bb5b9d65d17d7d495bef59577e50b412400821477bb56f2c098300\\\\ko_train_0/common_voice_ko_35845802.mp3', 'array': array([ 1.45519152e-11,  0.00000000e+00,  2.18278728e-11, ...,\n",
            "        4.60762531e-05,  3.03988345e-05, -1.03190541e-06]), 'sampling_rate': 16000}, 'sentence': 'ì–´ëŠë§ ê·¸ ë”ìš´ íŒ”ì›”ë„ í•˜ë£¨ë¥¼ ë‚¨ê¸°ê³  ë‹¤ ì§€ë‚˜ ë²„ë ¸ë‹¤.'}\n"
          ]
        }
      ],
      "source": [
        "print(common_voice[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91edc72d-08f8-4f01-899d-74e65ce441fc",
      "metadata": {
        "id": "91edc72d-08f8-4f01-899d-74e65ce441fc"
      },
      "source": [
        "\n",
        "* ëª¨ë¸ì— ë§ê²Œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” í•¨ìˆ˜:\n",
        "\n",
        "1. batch[\"audio\"]ë¥¼ í˜¸ì¶œí•˜ì—¬ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë‹¤ì‹œ ìƒ˜í”Œë§. ğŸ¤— DatasetsëŠ” í•„ìš”í•œ ëª¨ë“  ì¬ìƒ˜í”Œë§ ì‘ì—…ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜í–‰\n",
        "3. Feature extractorë¥¼ ì‚¬ìš©í•˜ì—¬ 1ì°¨ì› ì˜¤ë””ì˜¤ ë°°ì—´ì—ì„œ ë¡œê·¸ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì…ë ¥ íŠ¹ì„±ì„ ê³„ì‚°\n",
        "3. Tokenizerë¥¼ ì‚¬ìš©í•˜ì—¬ transcriptsë¥¼ ë ˆì´ë¸” idsë¡œ ì¸ì½”ë”©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6525c478-8962-4394-a1c4-103c54cce170",
      "metadata": {
        "id": "6525c478-8962-4394-a1c4-103c54cce170"
      },
      "outputs": [],
      "source": [
        "# def prepare_dataset(batch):\n",
        "#     # load and resample audio data from 48 to 16kHz\n",
        "#     audio = batch[\"audio\"]\n",
        "\n",
        "#     # compute log-Mel input features from input audio array\n",
        "#     batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "#     # encode target text to label ids\n",
        "#     batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "#     return batch\n",
        "\n",
        "def prepare_dataset(batch, feature_extractor, tokenizer):\n",
        "    # Load and resample audio data from 48 to 16kHz\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # Compute log-Mel input features from input audio array\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # Encode target text to label ids\n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70b319fb-2439-4ef6-a70d-a47bf41c4a13",
      "metadata": {
        "id": "70b319fb-2439-4ef6-a70d-a47bf41c4a13"
      },
      "source": [
        "* ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜\n",
        "    * ë°ì´í„°ì…‹ì˜ .map ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  í•™ìŠµ ì˜ˆì œì— ì ìš© ê°€ëŠ¥\n",
        "    * num_proc: ëª‡ ê°œì˜ CPU ì½”ì–´ë¥¼ ì‚¬ìš©í•  ì§€ë¥¼ ì§€ì •,num_procë¥¼ 1ë³´ë‹¤ í¬ê²Œ ì„¤ì •í•˜ë©´ ë‹¤ì¤‘ ì²˜ë¦¬ê°€ í™œì„±í™” (ë‹¤ì¤‘ ì²˜ë¦¬ë¡œ .map ë©”ì„œë“œê°€ ì¤‘ë‹¨ë˜ëŠ” ê²½ìš° num_proc=1ë¡œ ì„¤ì •í•˜ê³  ë°ì´í„°ì…‹ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬)\n",
        "\n",
        "* Datasetì˜ ì‚¬ì´ì¦ˆì— ë”°ë¼ì„œ 20~30 ì •ë„ ê±¸ë¦¼\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b",
      "metadata": {
        "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b",
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "ad6d83e9d32f44448d077a1685934cb9",
            "d9271509fb2a4562a7a83fb91039e4f4"
          ]
        },
        "outputId": "09d78a37-ae94-44f2-85c8-33f81fea2720"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad6d83e9d32f44448d077a1685934cb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/297 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9271509fb2a4562a7a83fb91039e4f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/131 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=2)\n",
        "\n",
        "common_voice = common_voice.map(\n",
        "    prepare_dataset,\n",
        "    remove_columns=common_voice.column_names[\"train\"],\n",
        "    num_proc=2,\n",
        "    fn_kwargs={\"feature_extractor\": feature_extractor, \"tokenizer\": tokenizer}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4be572c",
      "metadata": {
        "id": "c4be572c",
        "outputId": "27d5006e-dff0-4cd9-98e4-7f4e9b4dbc56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_features', 'labels'],\n",
              "    num_rows: 297\n",
              "})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "common_voice[\"train\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "263a5a58-0239-4a25-b0df-c625fc9c5810",
      "metadata": {
        "id": "263a5a58-0239-4a25-b0df-c625fc9c5810"
      },
      "source": [
        "## í•™ìŠµ ë° ê²€ì¦\n",
        "\n",
        "\n",
        "* í›ˆë ¨ íŒŒì´í”„ë¼ì¸\n",
        "* [ğŸ¤— Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer)ê°€ ëŒ€ë¶€ë¶„ì˜ ì‘ì—…ì„ ì²˜ë¦¬:\n",
        "\n",
        "\n",
        "1. ë°ì´í„° collator ì •ì˜: ë°ì´í„° ì½œë ˆì´í„°ëŠ” ìš°ë¦¬ê°€ ì „ì²˜ë¦¬í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ëª¨ë¸ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” PyTorch í…ì„œë¡œ ì¤€ë¹„\n",
        "2. í‰ê°€ ì§€í‘œ: í‰ê°€ ì¤‘ì—ëŠ” ëª¨ë¸ì„ ê¸€ì ì˜¤ë¥˜ìœ¨  [word error rate (CER)](https://huggingface.co/metrics/cer)ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€\n",
        "3. ì‚¬ì „ í›ˆë ¨ëœ ì²´í¬í¬ì¸íŠ¸ load: ì‚¬ì „ í›ˆë ¨ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•˜ê³  í›ˆë ¨ì„ ìœ„í•´ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±\n",
        "4. í›ˆë ¨ êµ¬ì„± ì •ì˜: ğŸ¤— Trainerê°€ í›ˆë ¨ ìŠ¤ì¼€ì¤„ì„ ì •ì˜ì— ì‚¬ìš©\n",
        "\n",
        "* ë¯¸ì„¸ ì¡°ì •í•œ í›„ì—ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ëª¨ë¸ì„ í‰ê°€í•˜ì—¬ í•œêµ­ì–´ ìŒì„±ì„ ì˜¬ë°”ë¥´ê²Œ transcribe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d230e6d-624c-400a-bbf5-fa660881df25",
      "metadata": {
        "id": "8d230e6d-624c-400a-bbf5-fa660881df25"
      },
      "source": [
        "### Data Collator ì •ì˜\n",
        "\n",
        "* ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤ ìŒì„± ëª¨ë¸ì˜ ë°ì´í„° ì½œë ˆì´í„°\n",
        "    * Input_featuresì™€ labelsë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ ì°¨ë³„í™”\n",
        "    \n",
        "    - Input_features: feature extractorì— ì˜í•´ ì²˜ë¦¬\n",
        "    - labels: tokenizerì— ì˜í•´ ì²˜ë¦¬\n",
        "\n",
        "* Input_featuresëŠ” ì´ë¯¸ 30ì´ˆë¡œ íŒ¨ë”©ë˜ì–´ ìˆê³  íŠ¹ì„± ì¶”ì¶œê¸°ì— ì˜í•´ ê³ ì •ëœ ì°¨ì›ì˜ ë¡œê·¸ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜. ë”°ë¼ì„œ ìš°ë¦¬ê°€ í•´ì•¼ í•  ì¼ì€ input_featuresë¥¼ ë°°ì¹˜ ì²˜ë¦¬ëœ PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "\n",
        "* labelsëŠ” íŒ¨ë”©ë˜ì§€ ì•ŠìŒ ë¨¼ì € ë°°ì¹˜ ë‚´ì—ì„œ ìµœëŒ€ ê¸¸ì´ì— ë§ê²Œ ì‹œí€€ìŠ¤ë¥¼ íŒ¨ë”©í•˜ê³ , tokenizerì˜ .pad ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œí€€ìŠ¤ë¥¼ íŒ¨ë”© íŒ¨ë”© í† í°ì€ ì†ì‹¤ì„ ê³„ì‚°í•  ë•Œ ê³ ë ¤ë˜ì§€ ì•Šë„ë¡ -100ìœ¼ë¡œ ëŒ€ì²´. ê·¸ëŸ° ë‹¤ìŒ ë ˆì´ë¸” ì‹œí€€ìŠ¤ì˜ ì‹œì‘ì—ì„œ BOS í† í°ì„ ì˜ë¼ì„œ í›ˆë ¨ ì¤‘ì— ë‚˜ì¤‘ì— ì´ë¥¼ ì¶”ê°€\n",
        "\n",
        "* ì´ì „ì— ì •ì˜í•œ WhisperProcessorë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì„± ì¶”ì¶œê¸° ë° í† í¬ë‚˜ì´ì € ì‘ì—…ì„ ëª¨ë‘ ìˆ˜í–‰ ê°€ëŠ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5",
      "metadata": {
        "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cae7dbf-8a50-456e-a3a8-7fd005390f86",
      "metadata": {
        "id": "3cae7dbf-8a50-456e-a3a8-7fd005390f86"
      },
      "source": [
        "Data collator ì´ˆê¸°í™” ì§„í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc834702-c0d3-4a96-b101-7b87be32bf42",
      "metadata": {
        "id": "fc834702-c0d3-4a96-b101-7b87be32bf42"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d62bb2ab-750a-45e7-82e9-61d6f4805698",
      "metadata": {
        "id": "d62bb2ab-750a-45e7-82e9-61d6f4805698"
      },
      "source": [
        "### í‰ê°€ ì§€í‘œ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66fee1a7-a44c-461e-b047-c3917221572e",
      "metadata": {
        "id": "66fee1a7-a44c-461e-b047-c3917221572e"
      },
      "source": [
        "\n",
        "* ASR ì‹œìŠ¤í…œì„ í‰ê°€í•˜ê¸° ìœ„í•œ 'ì‚¬ì‹¤ìƒì˜' ì§€í‘œì¸ í•œ ë‹¨ì–´ ì˜¤ë¥˜ìœ¨(CER) ë©”íŠ¸ë¦­ì„ ì‚¬ìš©\n",
        "* ë” ë§ì€ ì •ë³´ëŠ” [ë¬¸ì„œ](https://huggingface.co/metrics/cer)ë¥¼ ì°¸ì¡°. ìš°ë¦¬ëŠ” ğŸ¤— Evaluateì—ì„œ CER ë©”íŠ¸ë¦­ì„ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22b4011-f31f-4b57-b684-c52332f92890",
      "metadata": {
        "id": "b22b4011-f31f-4b57-b684-c52332f92890",
        "colab": {
          "referenced_widgets": [
            "95a681cad8b642fd93b43022f837f63d"
          ]
        },
        "outputId": "2238dd6d-96b3-437a-a9de-6f5e84bbd1fd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a681cad8b642fd93b43022f837f63d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"cer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf2a825-6d9f-4a23-b145-c37c0039075b",
      "metadata": {
        "id": "daf2a825-6d9f-4a23-b145-c37c0039075b"
      },
      "source": [
        "###Â Pre-trained ëª¨ë¸ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "437a97fa-4864-476b-8abc-f28b8166cfa5",
      "metadata": {
        "id": "437a97fa-4864-476b-8abc-f28b8166cfa5"
      },
      "source": [
        "* ì‚¬ì „ í›ˆë ¨ëœ Whisper ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œ\n",
        "    * ì´ ì‘ì—…ì€ ğŸ¤— Transformersë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ìš° ê°„ë‹¨\n",
        "\n",
        "\n",
        "\n",
        "* ëª¨ë¸ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ëª¨ë¸ì„ 8ë¹„íŠ¸ë¡œ         \n",
        "    * ëª¨ë¸ì„ 1/4 ì •ë°€ë„(32ë¹„íŠ¸ì™€ ë¹„êµí–ˆì„ ë•Œ)ë¡œ ì–‘ìí™”í•˜ì—¬ ì„±ëŠ¥ ì†ì‹¤ì„ ìµœì†Œí™” [here](https://huggingface.co/blog/hf-bitsandbytes-integration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f",
      "metadata": {
        "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f",
        "outputId": "f9f1c990-f05d-48dc-a211-505bb0060ff6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        }
      ],
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name_or_path, load_in_8bit=True, device_map={\"\":0})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bR-_yaEOPsfQ",
      "metadata": {
        "id": "bR-_yaEOPsfQ"
      },
      "source": [
        "### ëª¨ë¸ì˜ í›„ì²˜ë¦¬\n",
        "\n",
        "1. í›ˆë ¨ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´ 8ë¹„íŠ¸ ëª¨ë¸ì— ëª‡ ê°€ì§€ í›„ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ì ìš©\n",
        "2. ëª¨ë¸ ë ˆì´ì–´ë¥¼ ë™ê²°, í›ˆë ¨ê³¼ ëª¨ë¸ì˜ ì•ˆì •ì„±ì„ ìœ„í•´ ë ˆì´ì–´ ì •ê·œí™”ì™€ ì¶œë ¥ ë ˆì´ì–´ë¥¼ float32ë¡œ ìºìŠ¤íŒ…\n",
        "\n",
        "(ëª¨ë¸ ì•ˆì •ì„±ê³¼ layer normalization ë¶„ì„, float32ë¡œ ìºìŠ¤íŒ… í•˜ëŠ” ì´ìœ )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cl_ZQualPt9R",
      "metadata": {
        "id": "Cl_ZQualPt9R",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p0Ja2e__OX02",
      "metadata": {
        "id": "p0Ja2e__OX02"
      },
      "source": [
        "* Whisper ëª¨ë¸ì€ ì¸ì½”ë”ì— ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì²´í¬í¬ì¸íŒ…ì€ grad ì—°ì‚°ì„ ë¹„í™œì„±. ì´ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì…ë ¥ì„ íŠ¹ë³„íˆ trainableí•˜ê²Œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bmpeiajSOWCy",
      "metadata": {
        "id": "bmpeiajSOWCy",
        "outputId": "94947ae5-4739-4547-a8ae-3d9fe75c461a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x1d1d8658520>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_inputs_require_grad(module, input, output):\n",
        "    output.requires_grad_(True)\n",
        "\n",
        "model.model.encoder.conv1.register_forward_hook(make_inputs_require_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vjl4j4RJPmPR",
      "metadata": {
        "id": "Vjl4j4RJPmPR"
      },
      "source": [
        "### Low-rank adapters (LoRA)ë¥¼ ëª¨ë¸ì— ì ìš©\n",
        "\n",
        "* peftì—ì„œ get_peft_model ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ PeftModelì„ ë¡œë“œí•˜ê³  ì €í¬ê°€ ì €ì°¨ì› ì–´ëŒ‘í„°(LoRA)ë¥¼ ì‚¬ìš©í•  ê²ƒì„ì„ ì§€ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DQtpDPRHPyOL",
      "metadata": {
        "id": "DQtpDPRHPyOL",
        "outputId": "eee9345a-bb81-402a-8048-c3aacf8d843f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 15,728,640 || all params: 1,559,033,600 || trainable%: 1.0089\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(r=32, lora_alpha=64, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3906d436",
      "metadata": {
        "id": "3906d436"
      },
      "source": [
        "**1%**ì˜ í•™ìŠµ parameterë¥¼ ì‚¬ìš©í•˜ì˜€ê³  **Parameter-Efficient Fine-Tuning**ë¥¼ ì ìš©\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06",
      "metadata": {
        "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06"
      },
      "source": [
        "### í›ˆë ¨ êµ¬ì„± ì •ì˜"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c21af1e9-0188-4134-ac82-defc7bdcc436",
      "metadata": {
        "id": "c21af1e9-0188-4134-ac82-defc7bdcc436"
      },
      "source": [
        "\n",
        "ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œëŠ” í›ˆë ¨ê³¼ ê´€ë ¨ëœ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ì •ì˜ í›ˆë ¨ ì¸ìì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ í•´ë‹¹ ë¬¸ì„œë¥¼ ì°¸ì¡° Seq2SeqTrainingArguments [docs](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a",
      "metadata": {
        "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"reach-vb/test\",  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
        "    learning_rate=1e-3,\n",
        "    warmup_steps=50,\n",
        "    num_train_epochs=1,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    fp16=True,\n",
        "    per_device_eval_batch_size=8,\n",
        "    generation_max_length=128,\n",
        "    logging_steps=100,\n",
        "    max_steps=100, # only for testing purposes, remove this from your final run :)\n",
        "    remove_unused_columns=False,  # required as the PeftModel forward doesn't have the signature of the wrapped model's forward\n",
        "    label_names=[\"labels\"],  # same reason as above\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a944d8-3112-4552-82a0-be25988b3857",
      "metadata": {
        "id": "b3a944d8-3112-4552-82a0-be25988b3857"
      },
      "source": [
        "\n",
        "* PEFTë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì—ëŠ” ëª‡ ê°€ì§€ ì£¼ì˜ê°€ í•„ìš”\n",
        "\n",
        "1. PeftModelì˜ forwardê°€ ê¸°ë³¸ ëª¨ë¸ì˜ forwardì˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ ìƒì†í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— remove_unused_columns=False ë° label_names=[\"labels\"]ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •\n",
        "2.INT8 í›ˆë ¨ì—ëŠ” ìë™ ìºìŠ¤íŒ…ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— Trainerì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ ì œê³µë˜ëŠ” predict_with_generate í˜¸ì¶œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìë™ ìºìŠ¤íŒ…ì´ ìë™ìœ¼ë¡œ ì ìš©ë˜ì§€ ì•ŠìŒ\n",
        "3. ìë™ ìºìŠ¤íŒ…ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ Seq2SeqTrainerì— compute_metricsë¥¼ ì „ë‹¬í•  ìˆ˜ ì—†ìŒ. ë”°ë¼ì„œ Trainerë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ëŠ” ë™ì•ˆ compute_metricsë¥¼ ì£¼ì„ ì²˜ë¦¬ í•„ìš”\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d546d7fe-0543-479a-b708-2ebabec19493",
      "metadata": {
        "id": "d546d7fe-0543-479a-b708-2ebabec19493",
        "outputId": "f24abc46-f71d-411d-e716-ea3190ab42e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer, TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
        "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
        "\n",
        "# This callback helps to save only the adapter weights and remove the base model weights.\n",
        "class SavePeftModelCallback(TrainerCallback):\n",
        "    def on_save(\n",
        "        self,\n",
        "        args: TrainingArguments,\n",
        "        state: TrainerState,\n",
        "        control: TrainerControl,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        checkpoint_folder = os.path.join(args.output_dir, f\"{PREFIX_CHECKPOINT_DIR}-{state.global_step}\")\n",
        "\n",
        "        peft_model_path = os.path.join(checkpoint_folder, \"adapter_model\")\n",
        "        kwargs[\"model\"].save_pretrained(peft_model_path)\n",
        "\n",
        "        pytorch_model_path = os.path.join(checkpoint_folder, \"pytorch_model.bin\")\n",
        "        if os.path.exists(pytorch_model_path):\n",
        "            os.remove(pytorch_model_path)\n",
        "        return control\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=common_voice[\"train\"],\n",
        "    eval_dataset=common_voice[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    # compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    callbacks=[SavePeftModelCallback],\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de",
      "metadata": {
        "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de",
        "outputId": "a469629e-eb68-47de-dc61-5c1a659a6191"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\AEO\\anaconda3\\envs\\gpuconda\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "C:\\AEO\\anaconda3\\envs\\gpuconda\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "C:\\AEO\\anaconda3\\envs\\gpuconda\\lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:694: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 16:42, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.541300</td>\n",
              "      <td>0.231048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.5412639236450195, metrics={'train_runtime': 1017.2357, 'train_samples_per_second': 0.786, 'train_steps_per_second': 0.098, 'total_flos': 1.6866147262464e+18, 'train_loss': 0.5412639236450195, 'epoch': 2.6315789473684212})"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8iqXhUiuBQCs",
      "metadata": {
        "id": "8iqXhUiuBQCs"
      },
      "source": [
        "Fine-tuningí•œ ëª¨ë¸ì„ Hugging Face Hubì— ì €ì¥í•©ë‹ˆë‹¤. ë‚˜ì¤‘ì— ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ í¸í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0576aa2a",
      "metadata": {
        "id": "0576aa2a",
        "colab": {
          "referenced_widgets": [
            "07b05185fc8c4d51a9be1f16e095d33c"
          ]
        },
        "outputId": "29072fbc-f838-4776-c37f-56ff92bd2cd2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07b05185fc8c4d51a9be1f16e095d33c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/63.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/ZeroWater93/whisper-large-v2-korea-common_13/commit/71992e7d98bf7aaa1135f11a84742d63d4b80df3', commit_message='Upload model', commit_description='', oid='71992e7d98bf7aaa1135f11a84742d63d4b80df3', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peft_model_id = \"ZeroWater93/whisper-large-v2-korea-common_13\"\n",
        "model.push_to_hub(peft_model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SlyyOGnPgi_I",
      "metadata": {
        "id": "SlyyOGnPgi_I"
      },
      "source": [
        "# í‰ê°€ ë° ê²€ì¦"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Kzfg2qoXgrhg",
      "metadata": {
        "id": "Kzfg2qoXgrhg"
      },
      "source": [
        "Finetuningì„ ì„±ê³µì ìœ¼ë¡œ í–ˆìœ¼ë©´ ì´ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ ì €í¬ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ê³  CER(Character Error Rate) ê³„ì‚°\n",
        "\n",
        "í…ŒìŠ¤íŠ¸ ìœ ì˜í•  ì ë“¤:\n",
        "\n",
        "1. predict_with_generate í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ìì²´ì ìœ¼ë¡œ torch.cuda.amp.autocast()ë¥¼ ì‚¬ìš©í•˜ì—¬ eval ë£¨í”„ë¥¼ êµ¬í˜„\n",
        "\n",
        "2. ê¸°ë³¸ ëª¨ë¸ì´ ë™ê²°ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— PEFT ëª¨ë¸ì€ ë•Œë¡œ ë””ì½”ë”© ì¤‘ì— ì–¸ì–´ë¥¼ ì¸ì‹í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë””ì½”ë”© ì‹œì‘ í† í°ì— ë²ˆì—­ ì¤‘ì¸ ì–¸ì–´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •. ì´ ì‘ì—…ì€ forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"Marathi\", task=\"transcribe\")ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰í•˜ê³  model.generate í˜¸ì¶œì— ì´ë¥¼ ì „ë‹¬\n",
        "\n",
        "Transcribeë¥¼ ì§„í–‰ ğŸ”¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273a996c",
      "metadata": {
        "id": "273a996c",
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "5fe5cae6805543f78b70a88555eee745"
          ]
        },
        "outputId": "5d69a065-98b6-4fd6-b708-8b51b61f9216"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fe5cae6805543f78b70a88555eee745",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/771 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\n                    Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\n                    quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\n                    in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to\n                    `from_pretrained`. Check\n                    https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                    for more details.\n                    ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[72], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m peft_model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroWater93/whisper-large-v2-korea-common_13\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Use the same model ID as before.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m peft_config \u001b[38;5;241m=\u001b[39m PeftConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(peft_model_id)\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWhisperForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, peft_model_id)\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mC:\\AEO\\anaconda3\\envs\\gpuconda\\lib\\site-packages\\transformers\\modeling_utils.py:3627\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3624\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m infer_auto_device_map(model, dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdevice_map_kwargs)\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3627\u001b[0m         \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3629\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3630\u001b[0m     model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
            "File \u001b[1;32mC:\\AEO\\anaconda3\\envs\\gpuconda\\lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_8bit.py:86\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     83\u001b[0m         key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules_to_not_convert\n\u001b[0;32m     84\u001b[0m     }\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m---> 86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m            Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m            quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m            in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m            `from_pretrained`. Check\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m            https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m            for more details.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m            \"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m         )\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.37.2\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have a version of `bitsandbytes` that is not compatible with 8bit inference and training\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you have the latest version of `bitsandbytes` installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: \n                    Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\n                    quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\n                    in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to\n                    `from_pretrained`. Check\n                    https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                    for more details.\n                    "
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import WhisperForConditionalGeneration, Seq2SeqTrainer\n",
        "\n",
        "peft_model_id = \"ZeroWater93/whisper-large-v2-korea-common_13\" # Use the same model ID as before.\n",
        "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\n",
        "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "model.config.use_cache = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "401ceaa6",
      "metadata": {
        "id": "401ceaa6",
        "outputId": "ab751ca3-fc9f-4bca-95c1-761f4b96773e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 6/17 [01:37<02:59, 16.35s/it]"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
        "\n",
        "eval_dataloader = DataLoader(common_voice[\"test\"], batch_size=8, collate_fn=data_collator)\n",
        "forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=task)\n",
        "normalizer = BasicTextNormalizer()\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "normalized_predictions = []\n",
        "normalized_references = []\n",
        "\n",
        "model.eval()\n",
        "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = (\n",
        "                model.generate(\n",
        "                    input_features=batch[\"input_features\"].to(\"cuda\"),\n",
        "                    forced_decoder_ids=forced_decoder_ids,\n",
        "                    max_new_tokens=255,\n",
        "                )\n",
        "                .cpu()\n",
        "                .numpy()\n",
        "            )\n",
        "            labels = batch[\"labels\"].cpu().numpy()\n",
        "            labels = np.where(labels != -100, labels, processor.tokenizer.pad_token_id)\n",
        "            decoded_preds = processor.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "            decoded_labels = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "            predictions.extend(decoded_preds)\n",
        "            references.extend(decoded_labels)\n",
        "            normalized_predictions.extend([normalizer(pred).strip() for pred in decoded_preds])\n",
        "            normalized_references.extend([normalizer(label).strip() for label in decoded_labels])\n",
        "        del generated_tokens, labels, batch\n",
        "    gc.collect()\n",
        "wer = 100 * metric.compute(predictions=predictions, references=references)\n",
        "normalized_wer = 100 * metric.compute(predictions=normalized_predictions, references=normalized_references)\n",
        "eval_metrics = {\"eval/wer\": wer, \"eval/normalized_wer\": normalized_wer}\n",
        "\n",
        "print(f\"{wer=} and {normalized_wer=}\")\n",
        "print(eval_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j3XF0PzsCV0v",
      "metadata": {
        "id": "j3XF0PzsCV0v"
      },
      "source": [
        "## ë§ˆë¬´ë¦¬!\n",
        "\n",
        "Whisper ì²´í¬í¬ì¸íŠ¸ë¥¼ ë” ë¹ ë¥´ê³  ì €ë ´í•˜ê²Œ í›ˆë ¨í•˜ê³  CERì—ì„œ ê±°ì˜ ì†ì‹¤ì´ ì—†ë„ë¡ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ë°°ì›€\n",
        "\n",
        "PEFT (Pretraining Efficiently with Fine-Tuning)ë¥¼ ì‚¬ìš©í•˜ë©´ ìŒì„± ì¸ì‹ ì´ì™¸ì—ë„ ë‹¤ë¥¸ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì— ë™ì¼í•œ ê¸°ìˆ  ì„¸íŠ¸ë¥¼ ì ìš© ê°€ëŠ¥. ì•„ë˜ ë§í¬ì—ì„œ ìì„¸íˆ ì„¤ëª…: https://github.com/huggingface/peft ğŸ¤—"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06292a5c7aee497da4adf4bad7821023": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11ebc9c8a98a471fae03bbf78f266017": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "1c6783f29c6d4473a1f2f6936fa8682a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e39340a463a4a36aa5b89c468443340": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32268d5cfdbf4cada7ecf99f500d78e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "323d4ce1247e47ffa4d7402ae9d56187": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33b8358abdd84d2db2a676cd78e34e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e96669dc833348558eaba0a863000992",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_32268d5cfdbf4cada7ecf99f500d78e3",
            "value": ""
          }
        },
        "49d1a842d5374d7d90223a895dad23a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d7f2b46662614e7a86d5bb40ec8dfbca",
            "style": "IPY_MODEL_4d28829ac5fd43c0978fb4abdba1232a",
            "tooltip": ""
          }
        },
        "4d28829ac5fd43c0978fb4abdba1232a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "66b90e6bde694e819da181fc0536daf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74bfe188e1004755b580367771a08150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6783f29c6d4473a1f2f6936fa8682a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_323d4ce1247e47ffa4d7402ae9d56187",
            "value": "Connecting..."
          }
        },
        "8d7c7ef49aec459783389b840fe3a5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dcb31625fff4f7da6d28821ef535958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6ad995b0183445eb165aff824a649fa"
            ],
            "layout": "IPY_MODEL_11ebc9c8a98a471fae03bbf78f266017"
          }
        },
        "948d115a19b446cd9f75a7e5b8210571": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f7069bb8321494eb6d8184eade793f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_06292a5c7aee497da4adf4bad7821023",
            "style": "IPY_MODEL_d278e3ffc1504e5790aaf4250bbdc0fb",
            "value": true
          }
        },
        "d278e3ffc1504e5790aaf4250bbdc0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f2b46662614e7a86d5bb40ec8dfbca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de61db8206fe4a6da225263fe67d6fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb5347528f2440279d88be725e435df7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ee04cb67adc24431b9279db5dbfcd233",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e6ad995b0183445eb165aff824a649fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d7c7ef49aec459783389b840fe3a5c6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2e39340a463a4a36aa5b89c468443340",
            "value": "Invalid token passed!"
          }
        },
        "e96669dc833348558eaba0a863000992": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb5347528f2440279d88be725e435df7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee04cb67adc24431b9279db5dbfcd233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee3a40d801654eb7957204287584baca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b90e6bde694e819da181fc0536daf7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_948d115a19b446cd9f75a7e5b8210571",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
